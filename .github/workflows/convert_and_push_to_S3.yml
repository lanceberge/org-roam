name: Convert to HTML and Push to S3

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

  workflow_dispatch:


jobs:
  get_modified_files:
    runs-on: ubuntu-latest

    outputs:
      modified_files: ${{ steps.files_list.outputs.modified_files }}
      deleted_files: ${{ steps.files_list.outputs.deleted_files }}


    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0


      - name: Get Modified Files
        id: files_list
        run: |
          first_commit='${{ github.event.before }}'
          last_commit='${{ github.event.after }}'
          ALL_MODIFIED_FILES=$(git diff --name-status "$first_commit" "$last_commit")
          if [ -z "$ALL_MODIFIED_FILES" ]; then
              echo "No modified files. Exiting."
              exit 0
          fi

          # We will delete all files that were renamed and convert/write all
          # of the files that they got renamed to

          ## TODO optimization - only convert if there's a diff for the modified file
          ## otherwise do aws s3 mv
          ALL_RENAMED_FILES=$(echo "$ALL_MODIFIED_FILES" | grep -E '^R' || true)
          RENAMED_MODIFIED_FILES=""
          MODIFIED_ONLY_FILES=""
          RENAMED_DELETED_FILES=""
          ADDED_FILES=""
          DELETED_ONLY_FILES=""

          if [[ -n "$ALL_RENAMED_FILES" ]]; then
              RENAMED_MODIFIED_FILES=$(echo "$ALL_RENAMED_FILES" | cut -f3)
              RENAMED_DELETED_FILES=$(echo "$ALL_RENAMED_FILES" | cut -f2)
          fi

          MODIFIED_ONLY_FILES=$(echo "$ALL_MODIFIED_FILES" | grep -E '^M' | cut -f2 || true)
          ADDED_FILES=$(echo "$ALL_MODIFIED_FILES" | grep -E '^A' | cut -f2 || true)

          MODIFIED_FILES=$(echo "$MODIFIED_ONLY_FILES" "$RENAMED_MODIFIED_FILES" "$ADDED_FILES" | tr '\n' ' ')
          echo "modified_files=$MODIFIED_FILES" >> $GITHUB_OUTPUT

          echo "Modified Files:"
          echo "$MODIFIED_FILES"

          DELETED_ONLY_FILES=$(echo "$ALL_MODIFIED_FILES" | grep -E '^D' | cut -f2 || true)
          DELETED_FILES=$(echo "$DELETED_ONLY_FILES" "$RENAMED_DELETED_FILES" | tr '\n' ' ')
          echo "deleted_files=$DELETED_FILES" >> $GITHUB_OUTPUT

          echo "Deleted Files:"
          echo "$MODIFIED_FILES"


  write_to_s3:
    runs-on: ubuntu-latest
    needs: get_modified_files

    env:
      AWS_S3_BUCKET: "s3://braindump-bucket"


    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0


      - name: Configure AWS credentials
        if: ${{ needs.get_modified_files.outputs.modified_files != '' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: 'us-east-2'


        ## TODO only if there's .org files
      - name: Install Pandoc
        if: ${{ needs.get_modified_files.outputs.modified_files != '' }}
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc


      - name: Convert and Push
        if: ${{ needs.get_modified_files.outputs.modified_files != '' }}
        run: |
          echo "Running convert and push"
          for file in ${{ needs.get_modified_files.outputs.modified_files }}; do
              echo "Converting File:"
              echo "$file"
              if [[ "$file" == *.org ]]; then
                      HTML_FILE=${file%.org}.html
                      pandoc "$file" -o "$HTML_FILE" --wrap=none
                      file="$HTML_FILE"
              fi

              cmd="aws s3 cp $file $AWS_S3_BUCKET/$file"
              echo "Running: $cmd"
              eval $cmd
          done

          find "." -type f -name "*.html" -exec rm {} +


      - name: Delete Files
        if: ${{ needs.get_modified_files.outputs.deleted_files != '' }}
        run: |
          for file in ${{ needs.get_modified_files.outputs.deleted_files }}; do
              if [[ "$file" == *.org ]]; then
                      file=${file%.org}.html
              fi

              aws s3 rm "$AWS_S3_BUCKET/$file"
          done

# TODO set up a way to ignore files
